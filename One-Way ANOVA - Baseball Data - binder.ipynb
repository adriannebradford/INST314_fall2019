{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Way ANOVA\n",
    "In this notebook we will analyze batting data from Major League Baseball using one-way ANOVA.  We will look at:\n",
    "\n",
    "- variance testing to determine equal variance across groups\n",
    "- one-way ANOVA with both equal and unequal variances\n",
    "- one-way ANOVA with repeated measures\n",
    "- post hoc testing of assumptions (normality of residuals)\n",
    "- post hoc pairwise testing of means\n",
    "- non-parametric tests (testing of mean rank order)\n",
    "- effect size\n",
    "- power\n",
    "\n",
    "...and we'll look at some visualizations along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "- [One-Way ANOVA - unequal variances](#owunequal)\n",
    "- [One-Way ANOVA - equal variances - post season](#oweqpost)\n",
    "- [One-Way ANOVA - equal variances - regular season](#oweqpre)\n",
    "- [One-Way ANOVA - repeated measures](#repeated)\n",
    "- [One-way Non-parametric test (for non-normal or ordinal data)](#kruskal)\n",
    "- [Power Analysis](#power)\n",
    "\n",
    "### Topic Subsections (within the larger analyses)\n",
    "- [Testing Assumptions - Homogeneity of Variances](#levene)\n",
    "- [Testing Assumptions - Post Hoc examination of normality of residuals](#resid)\n",
    "- [Post Hoc Pairwise Comparisons - Tukey HSD](#tukey)\n",
    "- [Post Hoc Pairwise Comparisons - Bonferroni](#bonf)\n",
    "- [Post Hoc Pairwise Comparisons - Dunn Test (non-parametric analysis)](#dunn)\n",
    "- [Effect Size - R-squared](#rsq)\n",
    "- [Effect Size - non-parametric tests](#epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## load the libraries we'll need in the notebook\n",
    "\n",
    "library(tidyverse)\n",
    "library(magrittr)\n",
    "library(ggpubr) # containes line/dot plot for visualizing means\n",
    "library(DescTools) # contains levene's test function\n",
    "library(broom) # to tidy model output\n",
    "library(rcompanion) # for EpsilonSquared function\n",
    "library(pwr) # for power analysis\n",
    "library(tidyr) # for pivot_longer\n",
    "\n",
    "options(repr.plot.width=5, repr.plot.height=4) ## set options for plot size within the notebook -\n",
    "# this is only for jupyter notebooks, you can disregard this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Cleaning Data\n",
    "Before I get started with the ANOVA examples I am going to load and clean data.  In this example we're going to load the (rather large) baseball batting stats and player tables from data.world directly from their site via the internet.  We will then subset our data to 1920 and later (the so-called \"live ball era\") and use joins to add the player level stats (height, weight, handedness) to our batting stats.  Our batting stats data has one row for each player for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Read Sabremetrics Baseball data from data.world\n",
    "## NOTE: these are large datasets and may take 10+ minutes to load\n",
    "\n",
    "df_players <- read.csv(\"https://query.data.world/s/2lodzrpv2eyrgdvsih4udahoxpg3rx\", header=TRUE, stringsAsFactors=FALSE)\n",
    "\n",
    "df_batting <- read.csv(\"https://query.data.world/s/qbrtixcbxxuyxuqq5oq6tfrkxoaycs\", header=TRUE, stringsAsFactors=FALSE)\n",
    "\n",
    "df_batt_post <- read.csv(\"https://query.data.world/s/wrxv3xo54tvesrlfhf72jlfn2lxsm6\", header=TRUE, stringsAsFactors=FALSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## look at first rows of each df\n",
    "head(df_players)\n",
    "head(df_batt_post)\n",
    "head(df_batting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## look at the \"structure of our dfs - variable names and types\"\n",
    "\n",
    "str(df_players)\n",
    "str(df_batt_post)\n",
    "str(df_batting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#subset batting dfs to \"live ball era\" - 1920 and later\n",
    "df_batting <- df_batting  %>% filter(yearid >= 1920)\n",
    "df_batt_post <- df_batt_post  %>% filter(yearid >= 1920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# join player data (weight, height, handedness (bats / throws)) with \n",
    "# batting data (both general and post season) using playerid\n",
    "plyr_cols <- df_players  %>% select(playerid, weight, height, bats, throws) ## select to only cols from player tbl I want\n",
    "dfreg <- inner_join(df_batting, plyr_cols, by = \"playerid\") # join batting to plyr_cols for all rows that match\n",
    "dfpost <- inner_join(df_batt_post, plyr_cols, by = \"playerid\") # join post season batting stats to plyr_cols\n",
    "head(dfreg)\n",
    "head(dfpost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the data at a point where we can start the analysis.  We will use our player data as predictors for our batting statistics.\n",
    "\n",
    "## Beginning the analysis\n",
    "We will begin the analysis by looking at some summary statistics and visualizations of our variables of interest.  The first ANOVA test we will conduct is to look at regular season hits (h) by handedness during batting (bats).  Let's look at the distributions of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(dfreg$h)\n",
    "table(dfreg$bats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, no! We have NAs on our batting variable.  Let's remove those - instead of removing the rows that have NAs on *ANY* variable we'll only remove those rows that have NA on the hitting variable (h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## remove cases with NA value on dfreg$h\n",
    "dfreg %<>% drop_na(h)  ## note the  %<>% pipe operator - this pipes forward AND does assignment back \n",
    "                       ## will overwrite the dataframe you're manipulating\n",
    "## check our summary again\n",
    "summary(dfreg$h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have some missing data on our \"bats\" variable - notice the 2 in a column before B with no label?  Those are NA that are not coded as NA, they are blank character values - \"\".  Let's remove those too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## remove cases with empty character value on dfreg$bats\n",
    "dfreg %<>% filter(bats != \"\")  ## note the  %<>% pipe operator - this pipes forward AND does assignment back \n",
    "                       ## will overwrite the dataframe you're manipulating\n",
    "## check our summary again\n",
    "table(dfreg$bats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we might finally be done with our data cleanup and ready to roll.  Lets start with looking at some graphical representations of our distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#frequency histogram\n",
    "dfreg  %>% ggplot(aes(h)) + \n",
    "  geom_histogram(binwidth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, our distribution is a bit skewed, but let's move foward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#box plot\n",
    "dfreg  %>% ggplot(aes(y = h)) +\n",
    "        geom_boxplot() +\n",
    "        xlab(\"all players\") +\n",
    "          theme(axis.text.x=element_blank(),\n",
    "        axis.ticks.x=element_blank())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#grouped box plot\n",
    "dfreg %>% ggplot(aes(x = bats, y = h, fill = bats)) +\n",
    "        geom_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#distribution of means by groups\n",
    "dfreg %>% ggline(x = \"bats\", y = \"h\", \n",
    "       add = c(\"mean_se\", \"jitter\"),  add.params = list(color=\"bats\"),\n",
    "       ylab = \"Hits\", xlab = \"Player Handedness (batting)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is definitely skewed, but it looks like the means may be different.  To see if we can remove some of the skew, and make our analysis more appopriate for the data/meaning of the data, lets remove any observations where the player had 0 at bats (ab) because those players would have had no chance to have made a hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# subset to observations with at least one at bat (ab)\n",
    "\n",
    "dfreg2 <- dfreg %>% filter(ab > 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# look at a couple of our graphs again\n",
    "\n",
    "#frequency histogram\n",
    "dfreg2  %>% ggplot(aes(h)) + \n",
    "  geom_histogram(binwidth=10)\n",
    "\n",
    "#distribution of means by groups\n",
    "dfreg2 %>% ggline(x = \"bats\", y = \"h\", \n",
    "       add = c(\"mean_se\", \"jitter\"),  add.params = list(color=\"bats\"),\n",
    "       ylab = \"Hits\", xlab = \"Player Handedness (batting)\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be a bit better, but still skewed.  Let's move on and do our pre-checks of our assumptions:\n",
    "\n",
    "## Pre-check - Assumptions\n",
    "- DV is numeric (interval or ratio) - yes, number of hits by player by year\n",
    "- No extreme outliers - nothing looks too bad\n",
    "- Normality __*of residuals*__ - can't check this until after\n",
    "- Independence of Observations (random selection, different samples) - not entirely since there are multiple observations from players for different years, but the observations are not paired in this format.  We'll agree to violate this assumption.\n",
    "- Group sample sizes are approximately equal - equal enough, and large enough to not matter too much.\n",
    "\n",
    "AND....\n",
    "<a id=\"levene\"></a>\n",
    "- Homogeneity of Variance - Let's check this right now with Levene's test.\n",
    "\n",
    "Levene's Test is the same as var.test() we used with t-tests, however it tests the variances of multiple groups.\n",
    "\n",
    "Recall:\n",
    "\n",
    "$H_0:$ The variances in the groups are equal. <BR>\n",
    "$H_A:$ The variances in the groups are not equal.\n",
    "\n",
    "In this test, we sort of want to fail to reject null, because it's easier if our variances are equal and we don't need to make the adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#LeveneTest(DV ~ IV, data = your data frame)\n",
    "\n",
    "LeveneTest(h ~ bats, data = dfreg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our p-value is very, very low - so we reject the null hypothesis.  The null hypothesis here is that the variances of each group are equal - so our variances are unequal.  This means we need to use the Welch's ANOVA for unequal variances.\n",
    "<a id=\"owunequal\"></a>\n",
    "## One-way ANOVA time! (unequal variances)\n",
    "We are finally ready to run our first ANOVA analysis.  We'll set our alpha at 0.05.  Based on the results of Levene's Test we have unequal variances.  To use the Welch's ANOVA we use the function oneway.test()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# oneway.test(DV ~ IV, data = your data frame)\n",
    "oneway.test(h ~ bats, data = dfreg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output doesn't give us all of the sum of squares and the mean sum of squares.  We get the F-value, the numerator and denominator degrees of freedom, and the p-value.  Our p-value is much lower than alpha and therefore we reject the null hypothesis.  This means that the mean number of hits between batter handedness (left-handed, right-handed, or both) is statistically different.  We'll later look at if it's actually substantively significant in a standardized way, but lets take a peak at the unstandardized difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfreg2 %>% group_by(bats) %>% summarize(mean_hits = mean(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right-handed batters hit on average 39 hits per season, while left-handed batters hit an average of 50 hits, and switch hitters hit an average of 55 hits per season.  This means that the difference between R and L are 11 hits, and between L and B is 5 hits.  Those seem somewhat significant to me.  We would look at the R-squared to see the standardized effect size (the proportion of variance explained by the IV) but we can't do that with the output of oneway.test() so I'm going to use the lm() (linear model) function.\n",
    "\n",
    "### R-squared (effect size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(lm(h ~ bats, data = dfreg2)) ## use summary to get the full output that includes r-squared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our R-squared shows that handedness of the batter only accounts for 1% of the variance in number of hits, even though the result is statistically significant, and the unstandardized difference looked substantively signficant, the variance explained is very very low (almost 0) which means that handedness doesn't influence number of hits.  We'll return to this example when we look at non-parametric tests, as our data was extremely skewed.\n",
    "\n",
    "<a id = \"oweqpost\"></a>\n",
    "\n",
    "## One-way ANOVA - equal variances - post season\n",
    "This time we're going to run an ANOVA analysis using the aov() function, which assumes equal variances.  Given the current World Series matchup - the Houston Astros vs. the Washington Nationals - we'll comparing hitting stats between those two teams during the offseason.  First we'll need to subset our data to just include those teams.  We'll include the Montreal Expos stats with the Washington Nationals group - so we'll need a bit of data cleaning.  We'll look at the teamid variable - we want \"HOU\" for the Astros and \"WAS\" and \"MON\" for the Nationals, but \"MON\" will be a third group in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfpost_sub <- dfpost %>% \n",
    "                    filter(teamid %in% c(\"HOU\", \"WAS\", \"MON\")) \n",
    "table(dfpost_sub$teamid) ## check to make sure the distribution team variable looks the way we want it to after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll run a Levene's test to check for homogeneity of variances, but we'll assume equal variances in our ANOVA analysis either way, for the purposes of the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LeveneTest(h ~ as.factor(teamid), data = dfpost_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fail to reject the null hypothesis, therefore we can assume our variances are equal. Let's take a look at our distribution of hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## check means by team\n",
    "dfpost_sub %>% group_by(teamid) %>% summarize(mean_hits = mean(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#grouped box plot\n",
    "dfpost_sub %>% ggplot(aes(x = teamid, y = h, fill = teamid)) +\n",
    "        geom_boxplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## line plot\n",
    "#distribution of means by groups\n",
    "dfpost_sub %>% ggline(x = \"teamid\", y = \"h\", \n",
    "       add = c(\"mean_se\", \"jitter\"),  add.params = list(color=\"teamid\"),\n",
    "       ylab = \"Hits\", xlab = \"Team\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like there's a lot going on here, let's see what our results say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use aov(DV ~ IV, data = dataset) to run ANOVA.  Then look at summary() for full results. \n",
    "\n",
    "WSaov = aov(h ~ teamid, data=dfpost_sub)\n",
    "summary(WSaov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no statistically significant difference in hitting between HOU, WAS, and the old Montreal Expos during the post-season.  \n",
    "<a id = \"oweqpre\"></a>\n",
    "## One-way ANOVA - equal variances - regular season\n",
    "Let's look at a different variable, home runs (HR) during the regular season by weight.  Since weight is a numerical variable we will need to use cut() to make it into a factor with levels that are weight ranges.  We'll start by looking at the distribution of weight to determine our cuts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(dfreg$weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two concerning things here - 1) it seems unlikely that a baseball player weighed 65 pounds - possible outlier? - and 2) we have 7 NAs.  Let's look at a box plot to see if we do have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfreg %>% ggplot(aes(y = weight)) +\n",
    "        geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That observation with a weight of 65 is a clear outlier, so let's drop him and the NAs before we move forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# drop NAs and observations with weights lower than 100\n",
    "dfreg3 <- dfreg %>% drop_na(weight) \n",
    "summary(dfreg3$weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll make our cuts.  I'm going to do my groups as (120, 175] (175, 200] (200, 225] (225, 250] (250, Inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wtcut <- c(-Inf,175,200,225,250,Inf) # define cut points\n",
    "wtlbls <- c(\"less than 175lbs\", \"175 - 200lbs\", \"200 - 225lbs\", \"225 - 250lbs\", \"more than 250lbs\" ) # create descriptive labels\n",
    "dfreg3 %<>% mutate(wt_cut = cut(weight, br= wtcut, label = wtlbls)) # use mutate to create new variable with the weight categories\n",
    "table(dfreg3$wt_cut) #inspect the results\n",
    "\n",
    "## I'm also going to filter out the players with 0 at bats\n",
    "dfreg3 %<>% filter(ab>0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look at the distribution of HR (home runs) by weight categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# means by group\n",
    "\n",
    "dfreg3 %>% group_by(wt_cut) %>% summarize(mean_hr = mean(hr)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## line plot\n",
    "#distribution of means by groups\n",
    "dfreg3 %>% ggline(x = \"wt_cut\", y = \"hr\", \n",
    "       add = c(\"mean_se\", \"jitter\"),  add.params = list(color=\"wt_cut\"),\n",
    "       ylab = \"Home Runs\", xlab = \"Weight\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there may be an association here, lets run our ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# use aov(DV ~ IV, data = dataset) to run ANOVA.  Then look at summary() for full results. \n",
    "\n",
    "wt_hr_aov = aov(hr ~ wt_cut, data=dfreg3)\n",
    "summary(wt_hr_aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a statistically significant difference in mean home runs by weight.  But is the difference substantively significant?  Let's look at r-squared.  \n",
    "\n",
    "<a id = \"rsq\"></a>\n",
    "### R-squared\n",
    "We know that $r^2 = \\frac{SS_{between}}{SS_{total}}$, so we can calculate it from the saved output of the ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at structure of aov result to locate the pieces of data we need\n",
    "# first use the tidy function from broom to \"tidy\" the aov output\n",
    "tidyout <- tidy(wt_hr_aov)\n",
    "str(tidyout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate with aov output\n",
    "ss_group <- tidyout$sumsq[1]\n",
    "ss_total <- sum(tidyout$sumsq)\n",
    "\n",
    "\n",
    "R_squared <- ss_group / ss_total\n",
    "            \n",
    "R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use lm() function\n",
    "wt_ht <- lm(hr ~ wt_cut, data=dfreg3)\n",
    "\n",
    "anova(wt_ht)\n",
    "summary(wt_ht)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either way we calculate it, our R-squared reflects no substantive significance - 1.8% of the variance in number of HRs is explained by player weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're wondering which groups are better at HRs / which groups have statitistically signficant paired differences.  Let's run our post-hoc pairwise comparisons.\n",
    "<a id = \"tukey\"></a>\n",
    "### Post-Hoc Pairwise Comparisons - Tukey HSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#use the TukeyHSD function and pass it your saved ANOVA output.\n",
    "\n",
    "TukeyHSD(wt_hr_aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like all of our pairwise comparisons are significant except the one between people more than 250 with the groups of 200-225 and 225-250.  We'll try Bonferroni too.\n",
    "<a id = \"bonf\"></a>\n",
    "### Post-hoc Pairwise Comparisons - Bonferroni Adjustment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for bonferroni we use the function pairwise.t.test with the p.adj argument set to \"bonf\"\n",
    "pairwise.t.test(dfreg3$hr, dfreg3$wt_cut, p.adj = \"bonf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are the same in terms of what's significant, but the p-values are slightly higher.\n",
    "<a id = \"resid\"></a>\n",
    "### Post Hoc Assumptions Test - Normality of Residuals\n",
    "\n",
    "You'll recall that one of our assumptions with ANOVA is the normality of the residuals.  We can't test that prior to conducting the analysis, so we have to look at it afterwards.  We'll use the plot() function with our aov output to graphically check this assumption. It is the Second plot (the QQ plot) that we check for normality of residuals and compare our line of residual points to the diagonal reference line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(wt_hr_aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As could be expected with our heavy amount of 0 values, and our skewed distribution of hr, our residuals deviate significantly from normality.  This means that our ANOVA results may not be valid, due to the violation of this assumption.\n",
    "<a id = \"repeated\"></a>\n",
    "## One-way Repeated Measures ANOVA\n",
    "\n",
    "Let's look at some paired data.  We'll look at HRs for players who played in the off-season compared to their regular season stats.  Specifically let's look at HRs among people who have at least one 1 HR in the regular season (to hopefully deal with some of the skewness).  In order to deal with the unequal number of games, we'll do HR/at bats to standardize the DV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join regular season stats to everyone who played in the offseason, using both playerid and year.\n",
    "dfjoin <- left_join(dfpost, dfreg, by = c(\"playerid\",\"yearid\"))\n",
    "head(dfjoin)\n",
    "# note our post seasons stats are now .x and our regular season stats are .y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to only those who had at least one HR in regular season and make standardized hr/ab variable\n",
    "dfjoin %<>% filter(hr.y > 0) %>%  # at least one hr in regular season\n",
    "                mutate(stdhr_reg = hr.y/ab.y) %>%  # create std. hr variable for regular season\n",
    "                mutate(stdhr_post = hr.x/ab.x) # create std. hr variable for post season\n",
    "#check summary stats\n",
    "summary(dfjoin[c(\"stdhr_reg\", \"stdhr_post\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NAs\n",
    "dfjoin %<>% drop_na(stdhr_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're doing a repeated measures ANOVA, so our \"grouping\" variable is time.  To do this we need to convert our data from \"wide\" to \"long\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wide format\n",
    "dfjoin_wide <- dfjoin %>% select(playerid, yearid, stdhr_reg, stdhr_post)\n",
    "head(dfjoin_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#long format\n",
    "dfjoin_long <- dfjoin_wide %>% pivot_longer(\n",
    "                                    cols = starts_with(\"stdhr\"),\n",
    "                                    names_to = \"season\",\n",
    "                                    names_prefix = \"stdhr_\",\n",
    "                                    values_to = \"HR\",\n",
    "                                    values_drop_na = TRUE)\n",
    "head(dfjoin_long, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run our ANOVA function with HR as the DV and season as our IV (time variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seas_hr_aov = aov(HR ~ season, data=dfjoin_long)\n",
    "summary(seas_hr_aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Players who played in the playoffs and had at least one home run in the regular season had a significantly different average number of homeruns per at bat between the regular season and the post season.  Let's look at the actual means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfjoin_long %>% group_by(season) %>% summarize(mean_hr = mean(HR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So fewer average HR per at bats in the post season.  Let's check our effect size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get r-squared from lm()\n",
    "summary(lm(HR ~ season, data=dfjoin_long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this result is not substantively significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"kruskal\"></a>\n",
    "## Non-parametric Tests (Kruskal-Wallis Test)\n",
    "\n",
    "Remember our non-parametric tests are not bound by the same assumptions as our parametric tests (most importantly normality) but they are less powerful, less detailed, and less specific.  \n",
    "\n",
    "Because of our normality violation in our first test, we'll retry the analysis using the Kruskal-Wallis Test (1/2).\n",
    "\n",
    "The test uses rank order vs. the actual values and compares means rank order by group.\n",
    "\n",
    "This test generates an H score (not F) - in R it says Chi Square, but it is an H statistic that uses the Chi Square method to determine statistical significance.\n",
    "\n",
    "We're returning back to our regular season hitting data, comparing by handedness.  Our DV is hits (h) and our IV is handedness for batting (bats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Kruskal-Wallis \n",
    "kruskal.test(h ~ bats, data = dfreg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a statistically significant difference - which means again that left-handed, right-handed, and switch hitters on average have significantly different numbers of hits.\n",
    "\n",
    "<a id = \"dunn\"></a>\n",
    "\n",
    "We can also look at the pairwise comparisons in the non-parametric test using the Dunn Test with the Bonferroni Adjustment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DunnTest (From DescTools package) DunnTest(DV, IV, method = \"bonferroni\")\n",
    "DunnTest(dfreg2$h, as.factor(dfreg2$bats), method=\"bonferroni\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the pairwise comparisons are significant - so all of the groups are significantly different from each other.\n",
    "\n",
    "<a id = \"epsilon\"></a>\n",
    "\n",
    "The final thing we can calculate for the non-parametric test is the effect size.  This version is epsilon-squared (instead of r-squared) but the interpretation is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate epsilonSquared(DV,IV)\n",
    "epsilonSquared(dfreg2$h, dfreg2$bats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to our results above, there is no substantive significance - the handedness of the batter only explains 1.5% of the variance in number of hits.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"power\"></a>\n",
    "\n",
    "## Power Analysis\n",
    "\n",
    "The final thing we will look at for one-way ANOVA is the power analysis.  \n",
    "\n",
    "The pwr.anova.test() function is very similar to the power functions we've used before, except the arguments are:\n",
    "\n",
    "- k = # of groups (categories in IV)\n",
    "- f = effect size (r-squared or epsilon-squared)\n",
    "- sig.level = alpha\n",
    "- power = power \n",
    "- n = sample size __PER GROUP__ (with the assumption that the groups will be equal sizes)\n",
    "\n",
    "As always, we supply 4 of the 5 things and R will calculate the fifth (set to NULL in the function call).  Typically we either calculate power of our analysis post hoc, or calculate the sample size we would need to achieve a certain power level for a particular effect size before conducting an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to know sample size, because they are unequal, we should use the n of the smallest group:\n",
    "table(dfreg2$bats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the power of our last, non-parametric test\n",
    "\n",
    "n = 5773\n",
    "\n",
    "pwr.anova.test(k=3, f=0.015, sig.level = 0.05, power = NULL, n = n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our analysis had a power of 0.41.  \n",
    "\n",
    "Let's see what sample size we would need to achieve a power of 0.8 with an very high effect size (r-squared) of 0.75 - 75% of the variance in the DV explained by the IV.  Our study will have 5 groups/levels of our IV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwr.anova.test(k=5, f=0.75, sig.level = 0.05, power = 0.8, n = NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would need 6 observations __PER GROUP__ for a total of 6 * 5 groups = 30 observations total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
